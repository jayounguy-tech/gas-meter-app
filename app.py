import streamlit as st
import streamlit.components.v1 as components  # å¼•å…¥å…ƒä»¶åº«ï¼Œç”¨æ–¼åŸ·è¡Œ JavaScript
from ultralytics import YOLO
from PIL import Image
import cv2
import numpy as np

# ==========================================
# 1. é é¢åŸºç¤è¨­å®š
# ==========================================
st.set_page_config(
    page_title="ç“¦æ–¯è¡¨ AI è¾¨è­˜",
    page_icon="ğŸ”¥",
    layout="centered",
    initial_sidebar_state="collapsed"
)

st.markdown("""
    <style>
    .stMetric {
        background-color: #f0f2f6;
        padding: 15px;
        border-radius: 10px;
        text-align: center;
    }
    [data-testid="stMetricValue"] {
        font-size: 2.5rem !important;
        color: #ff4b4b;
    }
    /* èª¿æ•´ç›¸æ©Ÿè¼¸å…¥æ¡†æ¨£å¼ */
    .stCameraInput {
        width: 100% !important;
    }
    </style>
    """, unsafe_allow_html=True)

# ==========================================
# 2. è¼‰å…¥æ¨¡å‹
# ==========================================
@st.cache_resource
def load_model():
    return YOLO('best.pt')

try:
    model = load_model()
except Exception as e:
    st.error(f"æ‰¾ä¸åˆ°æ¨¡å‹æª”æ¡ˆ best.ptï¼Œè«‹ç¢ºèªæª”æ¡ˆä½ç½®ï¼\néŒ¯èª¤: {e}")
    st.stop()

st.title("ğŸ”¥ ç“¦æ–¯è¡¨æŠ„è¡¨åŠ©æ‰‹")

# ==========================================
# 3. Javascript è£œå…‰ç‡ˆæ§åˆ¶é‚è¼¯
# ==========================================
def inject_torch_control(enable_torch):
    """
    æ³¨å…¥ JavaScript ä¾†æ§åˆ¶ç€è¦½å™¨çš„ MediaStream (è£œå…‰ç‡ˆ)
    """
    torch_state = "true" if enable_torch else "false"
    
    js_code = f"""
    <script>
    // è¨­å®šè¨ˆæ™‚å™¨ï¼Œå› ç‚ºç›¸æ©Ÿå¯èƒ½é‚„æ²’å®Œå…¨å•Ÿå‹•ï¼Œæ¯ 500ms æª¢æŸ¥ä¸€æ¬¡
    var attempts = 0;
    var torchInterval = setInterval(function() {{
        // å˜—è©¦æŠ“å– Streamlit çš„ video æ¨™ç±¤ (ä½æ–¼ iframe çˆ¶å±¤)
        var video = window.parent.document.querySelector('video');
        
        if (video && video.srcObject) {{
            var track = video.srcObject.getVideoTracks()[0];
            
            // æª¢æŸ¥ç€è¦½å™¨æ˜¯å¦æ”¯æ´ image-capture (è£œå…‰ç‡ˆ)
            var capabilities = track.getCapabilities();
            if (capabilities.torch) {{
                track.applyConstraints({{
                    advanced: [{{ torch: {torch_state} }}]
                }}).then(() => {{
                    console.log("è£œå…‰ç‡ˆç‹€æ…‹å·²åˆ‡æ›ç‚º: {torch_state}");
                }}).catch(err => {{
                    console.log("è£œå…‰ç‡ˆåˆ‡æ›å¤±æ•—: ", err);
                }});
                
                // æˆåŠŸæŠ“åˆ°å¾Œï¼Œæ¸…é™¤è¨ˆæ™‚å™¨
                clearInterval(torchInterval);
            }}
        }}
        
        attempts++;
        // å˜—è©¦ 10 æ¬¡ (5ç§’) å¾Œæ”¾æ£„ï¼Œé¿å…ç„¡é™åŸ·è¡Œ
        if (attempts > 10) clearInterval(torchInterval);
        
    }}, 500);
    </script>
    """
    # æ³¨å…¥ HTML/JS (é«˜åº¦è¨­ç‚º 0 éš±è—èµ·ä¾†)
    components.html(js_code, height=0)

# ==========================================
# 4. æ ¸å¿ƒè¾¨è­˜é‚è¼¯
# ==========================================
def is_inside(cx, cy, box_obj):
    if box_obj is None: return False
    bx1, by1, bx2, by2 = box_obj['coords']
    margin = 10
    in_box = (bx1 - margin < cx < bx2 + margin) and (by1 - margin < cy < by2 + margin)
    if not in_box: return False
    box_height = by2 - by1
    relative_y = (cy - by1) / box_height
    return 0.2 < relative_y < 0.8

def process_image_adaptive(image_input):
    current_conf = 0.4
    min_conf = 0.1
    step = 0.05
    imgsz_setting = 1280
    
    final_res_image = None
    final_reading = ""
    final_serial = ""
    used_conf = current_conf

    while current_conf >= min_conf:
        results = model(image_input, conf=current_conf, iou=0.5, imgsz=imgsz_setting, verbose=False)
        result = results[0]
        img_h, img_w = result.orig_shape
        
        gas_meter_box = None      
        serial_number_box = None  
        digits_found = []         

        for box in result.boxes:
            cls_id = int(box.cls[0])
            class_name = model.names[cls_id]
            conf = float(box.conf)
            x1, y1, x2, y2 = box.xyxy[0].tolist()
            
            if class_name == 'GasMeter':
                if gas_meter_box is None or conf > gas_meter_box['conf']:
                    gas_meter_box = {'coords': [x1, y1, x2, y2], 'conf': conf}
                    
            elif class_name == 'SerialNumber':
                pad_w, pad_h = 30, 10
                x1 = max(0, x1 - pad_w)
                y1 = max(0, y1 - pad_h)
                x2 = min(img_w, x2 + pad_w)
                y2 = min(img_h, y2 + pad_h)
                
                if serial_number_box is None or conf > serial_number_box['conf']:
                    serial_number_box = {'coords': [x1, y1, x2, y2], 'conf': conf}
            
            elif class_name.isdigit():
                center_x = (x1 + x2) / 2
                center_y = (y1 + y2) / 2
                digits_found.append({'val': class_name, 'cx': center_x, 'cy': center_y, 'x1': x1})

        reading_digits = []
        serial_digits = []
        for d in digits_found:
            if is_inside(d['cx'], d['cy'], gas_meter_box):
                reading_digits.append(d)
            elif is_inside(d['cx'], d['cy'], serial_number_box):
                serial_digits.append(d)

        reading_digits.sort(key=lambda x: x['x1'])
        serial_digits.sort(key=lambda x: x['x1'])
        
        temp_reading = "".join([d['val'] for d in reading_digits])
        temp_serial = "".join([d['val'] for d in serial_digits])
        
        condition_met = (len(temp_reading) >= 4) and (len(temp_serial) >= 6)
        
        final_reading = temp_reading
        final_serial = temp_serial
        used_conf = current_conf
        
        res_plotted = result.plot()
        final_res_image = cv2.cvtColor(res_plotted, cv2.COLOR_BGR2RGB)

        if condition_met:
            break
        
        current_conf -= step
        current_conf = round(current_conf, 2)

    return final_res_image, final_reading, final_serial, used_conf

# ==========================================
# 5. UI ä»‹é¢è¨­è¨ˆ
# ==========================================

# åœ–ç‰‡ä¾†æºé¸æ“‡
mode = st.radio("é¸æ“‡è¼¸å…¥æ–¹å¼ï¼š", ["ğŸ“¸ é–‹å•Ÿç›¸æ©Ÿ", "ğŸ“¤ ä¸Šå‚³ç…§ç‰‡"], horizontal=True)

image_source = None

if mode == "ğŸ“¸ é–‹å•Ÿç›¸æ©Ÿ":
    # -----------------------------------------------------
    # ğŸ”¦ è£œå…‰ç‡ˆé–‹é—œ (åƒ…åœ¨ç›¸æ©Ÿæ¨¡å¼é¡¯ç¤º)
    # -----------------------------------------------------
    col_t1, col_t2 = st.columns([0.4, 0.6])
    with col_t1:
        use_torch = st.toggle("ğŸ”¦ é–‹å•Ÿè£œå…‰ç‡ˆ (Android)", value=False)
        if use_torch:
            st.caption("å˜—è©¦é–‹å•Ÿé–ƒå…‰ç‡ˆ...")
    
    # æ³¨å…¥ JS æ§åˆ¶ç¢¼
    inject_torch_control(use_torch)
    
    # é¡¯ç¤ºç›¸æ©Ÿ
    camera_file = st.camera_input("è«‹å°æº–ç“¦æ–¯è¡¨æ‹æ”")
    if camera_file:
        image_source = Image.open(camera_file)
else:
    uploaded_file = st.file_uploader("é¸æ“‡ç…§ç‰‡", type=['jpg', 'png', 'jpeg'])
    if uploaded_file:
        image_source = Image.open(uploaded_file)

# ==========================================
# 6. åŸ·è¡Œè¾¨è­˜
# ==========================================
if image_source is not None:
    with st.spinner('ğŸ¤– AI æ­£åœ¨å˜—è©¦æœ€ä½³åƒæ•¸è¾¨è­˜ä¸­...'):
        processed_img, reading_str, serial_str, final_conf = process_image_adaptive(image_source)
    
    st.markdown("### ğŸ“Š è¾¨è­˜çµæœ")
    
    if final_conf < 0.4:
        st.caption(f"â„¹ï¸ å·²è‡ªå‹•é™ä½ä¿¡å¿ƒåº¦è‡³ **{final_conf}** ä»¥ç²å–æ›´å¤šæ•¸å­—")

    col1, col2 = st.columns(2)
    with col1:
        if len(reading_str) >= 4:
            st.metric("ğŸ”¥ åº¦æ•¸", reading_str)
        else:
            st.metric("ğŸ”¥ åº¦æ•¸", reading_str if reading_str else "N/A", delta="ä½æ•¸ä¸è¶³" if reading_str else "æœªåµæ¸¬", delta_color="inverse")
            
    with col2:
        if len(serial_str) >= 6:
            st.metric("ğŸ”¢ è¡¨è™Ÿ", serial_str)
        else:
             st.metric("ğŸ”¢ è¡¨è™Ÿ", serial_str if serial_str else "N/A", delta="ä½æ•¸ä¸è¶³" if serial_str else "æœªåµæ¸¬", delta_color="inverse")
            
    st.divider()

    img_tab1, img_tab2 = st.tabs(["ğŸ‘ï¸ è¾¨è­˜çµæœåœ–", "ğŸ“· åŸå§‹åœ–ç‰‡"])
    
    with img_tab1:
        st.image(processed_img, caption=f"AI ç¹ªè£½æ¡†ç·š (Conf: {final_conf})", use_container_width=True)
    with img_tab2:
        st.image(image_source, caption="åŸå§‹ä¸Šå‚³", use_container_width=True)
```

### âœ¨ æ›´æ–°é‡é»ï¼š
1.  **æ–°å¢ `import streamlit.components.v1 as components`ï¼š** é€™æ˜¯ç”¨ä¾†åŸ·è¡Œ JavaScript çš„æ¨¡çµ„ã€‚
2.  **æ–°å¢ `inject_torch_control` å‡½å¼ï¼š**
    * é€™æ®µç¨‹å¼ç¢¼æœƒåœ¨èƒŒæ™¯å·å·åŸ·è¡Œ JavaScriptã€‚
    * å®ƒæœƒå»å°‹æ‰¾ç€è¦½å™¨ä¸­çš„ `<video>` æ¨™ç±¤ï¼ˆä¹Ÿå°±æ˜¯ç›¸æ©Ÿç•«é¢ï¼‰ã€‚
    * å¦‚æœæ‰¾åˆ°ï¼Œå®ƒæœƒå˜—è©¦è¨­å®š `torch: true`ï¼ˆé–‹å•Ÿæ‰‹é›»ç­’ï¼‰ã€‚
    * å¦‚æœä¸æ”¯æ´ï¼ˆä¾‹å¦‚ iPhone æˆ–æ˜¯é›»è…¦ Webcamï¼‰ï¼Œå®ƒæœƒåœ¨ Console å ±éŒ¯ä½†ä¸æœƒè®“ç¶²é ç•¶æ©Ÿã€‚
3.  **ä»‹é¢æ–°å¢ Toggle é–‹é—œï¼š**
    * åœ¨ç›¸æ©Ÿæ¨¡å¼ä¸Šæ–¹å¤šäº†ä¸€å€‹ `ğŸ”¦ é–‹å•Ÿè£œå…‰ç‡ˆ (Android)` çš„é–‹é—œã€‚
    * **æ³¨æ„ï¼š** é€™å€‹é–‹é—œåˆ‡æ›æ™‚ï¼Œç¶²é æœƒé‡æ–°æ•´ç†æ˜¯æ­£å¸¸çš„ Streamlit è¡Œç‚ºã€‚

### ğŸš€ å¦‚ä½•æ›´æ–°ä¼ºæœå™¨ï¼Ÿ
1.  å°‡é€™ä»½æ–°ç¨‹å¼ç¢¼å­˜æˆ `app.py`ã€‚
2.  **Commit & Push** åˆ° GitHubã€‚
3.  **Streamlit Cloud** æœƒè‡ªå‹•åµæ¸¬åˆ°æ›´æ–°ä¸¦é‡æ–°éƒ¨ç½²ã€‚

å¿«å»ç”¨ Android æ‰‹æ©Ÿè©¦è©¦çœ‹å§ï¼(iPhone å¦‚æœæ²’åæ‡‰æ˜¯æ­£å¸¸çš„ç³»çµ±é™åˆ¶å–”)ã€‚
import streamlit as st
from ultralytics import YOLO
from PIL import Image
import cv2
import numpy as np

# ==========================================
# 1. é é¢åŸºç¤è¨­å®š
# ==========================================
st.set_page_config(
    page_title="ç“¦æ–¯è¡¨ AI è¾¨è­˜",
    page_icon="ğŸ”¥",
    layout="centered",
    initial_sidebar_state="collapsed"
)

st.markdown("""
    <style>
    .stMetric {
        background-color: #f0f2f6;
        padding: 15px;
        border-radius: 10px;
        text-align: center;
    }
    [data-testid="stMetricValue"] {
        font-size: 2.5rem !important;
        color: #ff4b4b;
    }
    .stCameraInput {
        width: 100% !important;
    }
    </style>
    """, unsafe_allow_html=True)

# ==========================================
# 2. è¼‰å…¥æ¨¡å‹
# ==========================================
@st.cache_resource
def load_model():
    return YOLO('best.pt')

try:
    model = load_model()
except Exception as e:
    st.error(f"æ‰¾ä¸åˆ°æ¨¡å‹æª”æ¡ˆ best.ptï¼Œè«‹ç¢ºèªæª”æ¡ˆä½ç½®ï¼\néŒ¯èª¤: {e}")
    st.stop()

st.title("ğŸ”¥ ç“¦æ–¯è¡¨æŠ„è¡¨åŠ©æ‰‹")

# ==========================================
# 3. æ ¸å¿ƒé‚è¼¯ (å«è‡ªé©æ‡‰è¿´åœˆ)
# ==========================================

def is_inside(cx, cy, box_obj):
    if box_obj is None: return False
    bx1, by1, bx2, by2 = box_obj['coords']
    margin = 10
    in_box = (bx1 - margin < cx < bx2 + margin) and (by1 - margin < cy < by2 + margin)
    if not in_box: return False
    box_height = by2 - by1
    relative_y = (cy - by1) / box_height
    return 0.2 < relative_y < 0.8

def process_image_adaptive(image_input):
    """
    è‡ªé©æ‡‰è™•ç†å‡½å¼ï¼š
    å¾ä¿¡å¿ƒåº¦ 0.4 é–‹å§‹å˜—è©¦ï¼Œ
    å¦‚æœ åº¦æ•¸ < 4ç¢¼ æˆ– è¡¨è™Ÿ < 6ç¢¼ï¼Œå°±é™ä½ä¿¡å¿ƒåº¦é‡è©¦ã€‚
    """
    
    # åˆå§‹è¨­å®š
    current_conf = 0.4   # èµ·å§‹ä¿¡å¿ƒåº¦
    min_conf = 0.1       # æœ€ä½åº•é™ (é¿å…é™åˆ° 0 æŠ“åˆ°ä¸€å †é›œè¨Š)
    step = 0.1           # æ¯æ¬¡é™ä½å¤šå°‘ (10%)
    imgsz_setting = 1280 # å›ºå®šé«˜è§£æåº¦
    
    final_res_image = None
    final_reading = ""
    final_serial = ""
    used_conf = current_conf

    # --- è‡ªé©æ‡‰è¿´åœˆ (Adaptive Loop) ---
    while current_conf >= min_conf:
        
        # 1. åŸ·è¡Œé æ¸¬
        results = model(image_input, conf=current_conf, iou=0.5, imgsz=imgsz_setting, verbose=False)
        result = results[0]
        img_h, img_w = result.orig_shape
        
        # 2. è§£æè³‡æ–™
        gas_meter_box = None      
        serial_number_box = None  
        digits_found = []         

        for box in result.boxes:
            cls_id = int(box.cls[0])
            class_name = model.names[cls_id]
            conf = float(box.conf)
            x1, y1, x2, y2 = box.xyxy[0].tolist()
            
            if class_name == 'GasMeter':
                if gas_meter_box is None or conf > gas_meter_box['conf']:
                    gas_meter_box = {'coords': [x1, y1, x2, y2], 'conf': conf}
                    
            elif class_name == 'SerialNumber':
                # è¡¨è™Ÿæ“´å¤§ç¯„åœ (Padding)
                pad_w, pad_h = 30, 10
                x1 = max(0, x1 - pad_w)
                y1 = max(0, y1 - pad_h)
                x2 = min(img_w, x2 + pad_w)
                y2 = min(img_h, y2 + pad_h)
                
                if serial_number_box is None or conf > serial_number_box['conf']:
                    serial_number_box = {'coords': [x1, y1, x2, y2], 'conf': conf}
            
            elif class_name.isdigit():
                center_x = (x1 + x2) / 2
                center_y = (y1 + y2) / 2
                digits_found.append({'val': class_name, 'cx': center_x, 'cy': center_y, 'x1': x1})

        # 3. åˆ†é…æ•¸å­—
        reading_digits = []
        serial_digits = []
        for d in digits_found:
            if is_inside(d['cx'], d['cy'], gas_meter_box):
                reading_digits.append(d)
            elif is_inside(d['cx'], d['cy'], serial_number_box):
                serial_digits.append(d)

        reading_digits.sort(key=lambda x: x['x1'])
        serial_digits.sort(key=lambda x: x['x1'])
        
        temp_reading = "".join([d['val'] for d in reading_digits])
        temp_serial = "".join([d['val'] for d in serial_digits])
        
        # 4. æª¢æŸ¥æ¢ä»¶ï¼šæ˜¯å¦æ»¿è¶³ä½æ•¸è¦æ±‚ï¼Ÿ
        # æ¢ä»¶ï¼šåº¦æ•¸ >= 4ç¢¼ ä¸” è¡¨è™Ÿ >= 6ç¢¼ (è¡¨è™Ÿæœ‰æ™‚å€™å¯èƒ½åªæœ‰ 5 æˆ– 8ï¼Œå¯è¦–æƒ…æ³èª¿æ•´)
        condition_met = (len(temp_reading) >= 4) and (len(temp_serial) >= 6)
        
        # æš«å­˜é€™æ¬¡çš„çµæœ
        final_reading = temp_reading
        final_serial = temp_serial
        used_conf = current_conf
        
        # ç”¢å‡ºåœ–ç‰‡
        res_plotted = result.plot()
        final_res_image = cv2.cvtColor(res_plotted, cv2.COLOR_BGR2RGB)

        # 5. åˆ¤æ–·æ˜¯å¦è¦è·³å‡ºè¿´åœˆ
        if condition_met:
            break  # æˆåŠŸæŠ“é½Šäº†ï¼Œæ”¶å·¥ï¼
        
        # å¦‚æœé‚„æ²’æŠ“é½Šï¼Œé™ä½ä¿¡å¿ƒåº¦ï¼Œæº–å‚™è·‘ä¸‹ä¸€è¼ª
        current_conf -= step
        
        # é˜²æ­¢æµ®é»æ•¸é‹ç®—èª¤å·®å°è‡´ç„¡é™è¿´åœˆ
        current_conf = round(current_conf, 2)

    return final_res_image, final_reading, final_serial, used_conf

# ==========================================
# 4. æ‰‹æ©Ÿç‰ˆä»‹é¢è¨­è¨ˆ
# ==========================================
# å°‡è¨­å®šéš±è—åœ¨æ‘ºç–Šé¸å–®ä¸­ï¼Œä¿æŒä»‹é¢ä¹¾æ·¨
with st.expander("âš™ï¸ è¾¨è­˜è¨­å®š (è¦ºå¾—ä¸æº–è«‹é»é€™)", expanded=False):
    conf_thres = st.slider("ä¿¡å¿ƒåº¦ (Confidence)", 0.1, 0.8, current_conf, 0.05)
    img_size = st.selectbox("è§£æåº¦ (Img Size)", [640, 960, 1280], index=2)

# åœ–ç‰‡ä¾†æºé¸æ“‡
mode = st.radio("é¸æ“‡è¼¸å…¥æ–¹å¼ï¼š", ["ğŸ“¸ é–‹å•Ÿç›¸æ©Ÿ", "ğŸ“¤ ä¸Šå‚³ç…§ç‰‡"], horizontal=True)

image_source = None

if mode == "ğŸ“¸ é–‹å•Ÿç›¸æ©Ÿ":
    camera_file = st.camera_input("è«‹å°æº–ç“¦æ–¯è¡¨æ‹æ”")
    if camera_file:
        image_source = Image.open(camera_file)
else:
    uploaded_file = st.file_uploader("é¸æ“‡ç…§ç‰‡", type=['jpg', 'png', 'jpeg'])
    if uploaded_file:
        image_source = Image.open(uploaded_file)

# ==========================================
# 5. åŸ·è¡Œèˆ‡é¡¯ç¤º
# ==========================================
if image_source is not None:
    # é¡¯ç¤ºè¼‰å…¥å‹•ç•«
    with st.spinner('ğŸ¤– AI æ­£åœ¨å˜—è©¦æœ€ä½³åƒæ•¸è¾¨è­˜ä¸­...'):
        processed_img, reading_str, serial_str, final_conf = process_image_adaptive(image_source)
    
    st.markdown("### ğŸ“Š è¾¨è­˜çµæœ")
    
    # é¡¯ç¤ºæœ€çµ‚ä½¿ç”¨çš„ä¿¡å¿ƒåº¦ (è®“ä½ çŸ¥é“ AI å¤šåŠªåŠ›)
    if final_conf < 0.4:
        st.caption(f"â„¹ï¸ å·²è‡ªå‹•é™ä½ä¿¡å¿ƒåº¦è‡³ **{final_conf}** ä»¥ç²å–æ›´å¤šæ•¸å­—")

    col1, col2 = st.columns(2)
    with col1:
        if len(reading_str) >= 4:
            st.metric("ğŸ”¥ åº¦æ•¸", reading_str)
        else:
            # å¦‚æœé™åˆ°æœ€ä½é‚„æ˜¯æŠ“ä¸åˆ°ï¼Œé¡¯ç¤ºç´…è‰²è­¦å‘Š
            st.metric("ğŸ”¥ åº¦æ•¸", reading_str if reading_str else "N/A", delta="ä½æ•¸ä¸è¶³" if reading_str else "æœªåµæ¸¬", delta_color="inverse")
            
    with col2:
        if len(serial_str) >= 6:
            st.metric("ğŸ”¢ è¡¨è™Ÿ", serial_str)
        else:
             st.metric("ğŸ”¢ è¡¨è™Ÿ", serial_str if serial_str else "N/A", delta="ä½æ•¸ä¸è¶³" if serial_str else "æœªåµæ¸¬", delta_color="inverse")
            
    st.divider()

    img_tab1, img_tab2 = st.tabs(["ğŸ‘ï¸ è¾¨è­˜çµæœåœ–", "ğŸ“· åŸå§‹åœ–ç‰‡"])
    
    with img_tab1:
        st.image(processed_img, caption=f"AI ç¹ªè£½æ¡†ç·š (Conf: {final_conf})", use_container_width=True)
    with img_tab2:
        st.image(image_source, caption="åŸå§‹ä¸Šå‚³", use_container_width=True)



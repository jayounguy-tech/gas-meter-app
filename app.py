import streamlit as st
import streamlit.components.v1 as components  # å¼•å…¥å…ƒä»¶åº«ï¼Œç”¨æ–¼åŸ·è¡Œ JavaScript
from ultralytics import YOLO
from PIL import Image
import cv2
import numpy as np
import os
import gdown  # è¨˜å¾—åœ¨ requirements.txt åŠ å…¥ gdown

# ==========================================
# 1. é é¢åŸºç¤è¨­å®š
# ==========================================
st.set_page_config(
    page_title="ç“¦æ–¯è¡¨ AI è¾¨è­˜",
    page_icon="ğŸ”¥",
    layout="centered",
    initial_sidebar_state="collapsed"
)

st.markdown("""
    <style>
    .stMetric {
        background-color: #f0f2f6;
        padding: 15px;
        border-radius: 10px;
        text-align: center;
    }
    [data-testid="stMetricValue"] {
        font-size: 2.5rem !important;
        color: #ff4b4b;
    }
    /* èª¿æ•´ç›¸æ©Ÿè¼¸å…¥æ¡†æ¨£å¼ */
    .stCameraInput {
        width: 100% !important;
    }
    </style>
    """, unsafe_allow_html=True)

# ==========================================
# 2. è‡ªå‹•ä¸‹è¼‰æ¨¡å‹ (è§£æ±º GitHub æª”æ¡ˆé™åˆ¶)
# ==========================================
@st.cache_resource
def load_model():
    model_path = 'best.pt'
    
    # æª¢æŸ¥æ¨¡å‹æ˜¯å¦å­˜åœ¨ï¼Œä¸å­˜åœ¨å°±ä¸‹è¼‰
    if not os.path.exists(model_path):
        st.info("â˜ï¸ æ­£åœ¨å¾ Google Drive ä¸‹è¼‰æ¨¡å‹ (ç´„ 40MB)ï¼Œåˆæ¬¡å•Ÿå‹•éœ€æ™‚è¼ƒé•·ï¼Œè«‹ç¨å€™...")
        try:
            # ---------------------------------------------------------
            # âš ï¸ è«‹å°‡ä¸‹æ–¹çš„ ID æ›æˆä½  Google Drive æª”æ¡ˆçš„ ID âš ï¸
            # ç¶²å€ç¯„ä¾‹: https://drive.google.com/file/d/1ABCDE.../view
            # ID å°±æ˜¯: 1ABCDE...
            # ---------------------------------------------------------
            file_id = '1-Wq7P73qno7w8sXWSKiC6lW4JG6uafpJ' 
            
            url = f'https://drive.google.com/uc?id={file_id}'
            gdown.download(url, model_path, quiet=False)
            st.success("âœ… ä¸‹è¼‰å®Œæˆï¼")
        except Exception as e:
            st.error(f"âŒ æ¨¡å‹ä¸‹è¼‰å¤±æ•—ï¼è«‹æª¢æŸ¥ Google Drive æ¬Šé™æ˜¯å¦è¨­ç‚ºå…¬é–‹ï¼Œæˆ– ID æ˜¯å¦æ­£ç¢ºã€‚\néŒ¯èª¤è¨Šæ¯: {e}")
            st.stop()
            
    return YOLO(model_path)

# å˜—è©¦è¼‰å…¥æ¨¡å‹
try:
    model = load_model()
except Exception as e:
    st.error(f"æ¨¡å‹è¼‰å…¥ç™¼ç”ŸéŒ¯èª¤: {e}")
    st.stop()

st.title("ğŸ”¥ ç“¦æ–¯è¡¨æŠ„è¡¨åŠ©æ‰‹")

# ==========================================
# 3. Javascript è£œå…‰ç‡ˆæ§åˆ¶é‚è¼¯
# ==========================================
def inject_torch_control(enable_torch):
    """
    æ³¨å…¥ JavaScript ä¾†æ§åˆ¶ç€è¦½å™¨çš„ MediaStream (è£œå…‰ç‡ˆ)
    """
    torch_state = "true" if enable_torch else "false"
    
    js_code = f"""
    <script>
    // è¨­å®šè¨ˆæ™‚å™¨ï¼Œå› ç‚ºç›¸æ©Ÿå¯èƒ½é‚„æ²’å®Œå…¨å•Ÿå‹•ï¼Œæ¯ 500ms æª¢æŸ¥ä¸€æ¬¡
    var attempts = 0;
    var torchInterval = setInterval(function() {{
        // å˜—è©¦æŠ“å– Streamlit çš„ video æ¨™ç±¤ (ä½æ–¼ iframe çˆ¶å±¤)
        var video = window.parent.document.querySelector('video');
        
        if (video && video.srcObject) {{
            var track = video.srcObject.getVideoTracks()[0];
            
            // æª¢æŸ¥ç€è¦½å™¨æ˜¯å¦æ”¯æ´ image-capture (è£œå…‰ç‡ˆ)
            var capabilities = track.getCapabilities();
            if (capabilities.torch) {{
                track.applyConstraints({{
                    advanced: [{{ torch: {torch_state} }}]
                }}).then(() => {{
                    console.log("è£œå…‰ç‡ˆç‹€æ…‹å·²åˆ‡æ›ç‚º: {torch_state}");
                }}).catch(err => {{
                    console.log("è£œå…‰ç‡ˆåˆ‡æ›å¤±æ•—: ", err);
                }});
                
                // æˆåŠŸæŠ“åˆ°å¾Œï¼Œæ¸…é™¤è¨ˆæ™‚å™¨
                clearInterval(torchInterval);
            }}
        }}
        
        attempts++;
        // å˜—è©¦ 10 æ¬¡ (5ç§’) å¾Œæ”¾æ£„ï¼Œé¿å…ç„¡é™åŸ·è¡Œ
        if (attempts > 10) clearInterval(torchInterval);
        
    }}, 500);
    </script>
    """
    # æ³¨å…¥ HTML/JS (é«˜åº¦è¨­ç‚º 0 éš±è—èµ·ä¾†)
    components.html(js_code, height=0)


# ==========================================
# 4. æ ¸å¿ƒè¾¨è­˜é‚è¼¯ (å« Paddingã€è‡ªé©æ‡‰ã€é˜²é‡ç–Š)
# ==========================================

def is_inside(cx, cy, box_obj):
    """åˆ¤æ–·æ•¸å­—ä¸­å¿ƒé»æ˜¯å¦åœ¨å¤§æ¡†å…§"""
    if box_obj is None: return False
    bx1, by1, bx2, by2 = box_obj['coords']
    margin = 10
    in_box = (bx1 - margin < cx < bx2 + margin) and (by1 - margin < cy < by2 + margin)
    if not in_box: return False
    
    # å‚ç›´éæ¿¾ï¼šæ•¸å­—æ‡‰è©²åœ¨æ¡†æ¡†é«˜åº¦çš„ä¸­é–“ 20%~80% å€åŸŸ
    box_height = by2 - by1
    relative_y = (cy - by1) / box_height
    return 0.2 < relative_y < 0.8

def remove_overlapping_digits(digits_list, iou_threshold=0.3):
    """
    ç§»é™¤é‡ç–Šçš„æ•¸å­—æ¡† (ä¿ç•™ä¿¡å¿ƒåº¦é«˜çš„)
    é‡å°ç“¦æ–¯è¡¨æ•¸å­—ï¼Œæˆ‘å€‘ç‰¹åˆ¥é—œæ³¨ X è»¸çš„é‡ç–Š
    """
    if not digits_list:
        return []
    
    # 1. ä¾ç…§ä¿¡å¿ƒåº¦ç”±é«˜åˆ°ä½æ’åº (å„ªå…ˆä¿ç•™é«˜ä¿¡å¿ƒçš„)
    sorted_digits = sorted(digits_list, key=lambda x: x['conf'], reverse=True)
    final_digits = []
    
    for current in sorted_digits:
        is_duplicate = False
        for kept in final_digits:
            # è¨ˆç®— X è»¸é‡ç–Š (1D IoU)
            # å…©å€‹å€é–“ [x1, x2] çš„é‡ç–Šé•·åº¦
            x_left = max(current['x1'], kept['x1'])
            x_right = min(current['x2'], kept['x2'])
            overlap_width = max(0, x_right - x_left)
            
            # è¨ˆç®—è¼ƒå°é‚£å€‹æ¡†çš„å¯¬åº¦
            min_width = min(current['x2'] - current['x1'], kept['x2'] - kept['x1'])
            
            # å¦‚æœé‡ç–Šè¶…éå¯¬åº¦çš„ 30%ï¼Œè¦–ç‚ºé‡è¤‡ (æˆ–è€…æ˜¯åŒ…å«é—œä¿‚)
            if min_width > 0 and (overlap_width / min_width) > iou_threshold:
                is_duplicate = True
                break
        
        if not is_duplicate:
            final_digits.append(current)
            
    return final_digits

def process_image_adaptive(image_input):
    current_conf = 0.4
    min_conf = 0.1
    step = 0.1
    imgsz_setting = 1280
    
    final_res_image = None
    final_reading = ""
    final_serial = ""
    used_conf = current_conf

    while current_conf >= min_conf:
        # 1. åŸ·è¡Œé æ¸¬
        # ã€é—œéµä¿®æ”¹ã€‘åŠ å…¥ agnostic_nms=Trueï¼Œå¼·åˆ¶è·¨é¡åˆ¥æŠ‘åˆ¶é‡ç–Š (ä¾‹å¦‚ 3 å’Œ 8 é‡ç–Šåªç•™ä¸€å€‹)
        results = model(image_input, conf=current_conf, iou=0.5, imgsz=imgsz_setting, agnostic_nms=True, verbose=False)
        result = results[0]
        img_h, img_w = result.orig_shape
        
        gas_meter_box = None      
        serial_number_box = None  
        digits_found = []         

        for box in result.boxes:
            cls_id = int(box.cls[0])
            class_name = model.names[cls_id]
            conf = float(box.conf)
            x1, y1, x2, y2 = box.xyxy[0].tolist()
            
            if class_name == 'GasMeter':
                if gas_meter_box is None or conf > gas_meter_box['conf']:
                    gas_meter_box = {'coords': [x1, y1, x2, y2], 'conf': conf}
                    
            elif class_name == 'SerialNumber':
                # Padding æ“´å¤§
                pad_w, pad_h = 10, 10
                x1 = max(0, x1 - pad_w)
                y1 = max(0, y1 - pad_h)
                x2 = min(img_w, x2 + pad_w)
                y2 = min(img_h, y2 + pad_h)
                
                if serial_number_box is None or conf > serial_number_box['conf']:
                    serial_number_box = {'coords': [x1, y1, x2, y2], 'conf': conf}
            
            elif class_name.isdigit():
                center_x = (x1 + x2) / 2
                center_y = (y1 + y2) / 2
                # å„²å­˜æ›´å¤šè³‡è¨Šä»¥ä¾¿å¾ŒçºŒéæ¿¾ (x1, x2)
                digits_found.append({
                    'val': class_name, 
                    'cx': center_x, 
                    'cy': center_y, 
                    'x1': x1, 
                    'x2': x2, 
                    'conf': conf
                })

        # 2. åˆæ­¥åˆ†é¡æ•¸å­—
        raw_reading_digits = []
        raw_serial_digits = []
        
        for d in digits_found:
            if is_inside(d['cx'], d['cy'], gas_meter_box):
                raw_reading_digits.append(d)
            elif is_inside(d['cx'], d['cy'], serial_number_box):
                raw_serial_digits.append(d)

        # 3. ã€é—œéµä¿®æ”¹ã€‘åŸ·è¡Œé˜²é‡ç–Šéæ¿¾ (ç§»é™¤å¹½éˆæ•¸å­—)
        reading_digits = remove_overlapping_digits(raw_reading_digits, iou_threshold=0.3)
        serial_digits = remove_overlapping_digits(raw_serial_digits, iou_threshold=0.3)

        # 4. æ’åºèˆ‡çµ„åˆ
        reading_digits.sort(key=lambda x: x['x1'])
        serial_digits.sort(key=lambda x: x['x1'])
        
        temp_reading = "".join([d['val'] for d in reading_digits])
        temp_serial = "".join([d['val'] for d in serial_digits])
        
        condition_met = (len(temp_reading) >= 4) and (len(temp_serial) >= 6)
        
        final_reading = temp_reading
        final_serial = temp_serial
        used_conf = current_conf
        
        res_plotted = result.plot()
        final_res_image = cv2.cvtColor(res_plotted, cv2.COLOR_BGR2RGB)

        if condition_met:
            break
        
        current_conf -= step
        current_conf = round(current_conf, 2)

    return final_res_image, final_reading, final_serial, used_conf

# ==========================================
# 4. æ‰‹æ©Ÿç‰ˆä»‹é¢è¨­è¨ˆ
# ==========================================

# å°‡è¨­å®šéš±è—åœ¨æ‘ºç–Šé¸å–®ä¸­ï¼Œä¿æŒä»‹é¢ä¹¾æ·¨
with st.expander("âš™ï¸ è¾¨è­˜è¨­å®š (è¦ºå¾—ä¸æº–è«‹é»é€™)", expanded=False):
    conf_thres = st.slider("ä¿¡å¿ƒåº¦ (Confidence)", 0.1, 0.8, 0.25, 0.05)
    img_size = st.selectbox("è§£æåº¦ (Img Size)", [640, 960, 1280], index=2)

# åœ–ç‰‡ä¾†æºé¸æ“‡
mode = st.radio("é¸æ“‡è¼¸å…¥æ–¹å¼ï¼š", ["ğŸ“¸ é–‹å•Ÿç›¸æ©Ÿ", "ğŸ“¤ ä¸Šå‚³ç…§ç‰‡"], horizontal=True)

image_source = None

if mode == "ğŸ“¸ é–‹å•Ÿç›¸æ©Ÿ":
    # -----------------------------------------------------
    # ğŸ”¦ è£œå…‰ç‡ˆé–‹é—œ (åƒ…åœ¨ç›¸æ©Ÿæ¨¡å¼é¡¯ç¤º)
    # -----------------------------------------------------
    col_t1, col_t2 = st.columns([0.4, 0.6])
    with col_t1:
        use_torch = st.toggle("ğŸ”¦ é–‹å•Ÿè£œå…‰ç‡ˆ (Android)", value=False)
        if use_torch:
            st.caption("å˜—è©¦é–‹å•Ÿé–ƒå…‰ç‡ˆ...")
    
    # æ³¨å…¥ JS æ§åˆ¶ç¢¼
    inject_torch_control(use_torch)
    
    camera_file = st.camera_input("è«‹å°æº–ç“¦æ–¯è¡¨æ‹æ”")
    if camera_file:
        image_source = Image.open(camera_file)
else:
    uploaded_file = st.file_uploader("é¸æ“‡ç…§ç‰‡", type=['jpg', 'png', 'jpeg'])
    if uploaded_file:
        image_source = Image.open(uploaded_file)

# ==========================================
# 5. åŸ·è¡Œèˆ‡é¡¯ç¤º
# ==========================================
if image_source is not None:
    # é¡¯ç¤ºè¼‰å…¥å‹•ç•«
    with st.spinner('ğŸ¤– AI æ­£åœ¨å˜—è©¦æœ€ä½³åƒæ•¸è¾¨è­˜ä¸­...'):
        processed_img, reading_str, serial_str, final_conf = process_image_adaptive(image_source)
    
    st.markdown("### ğŸ“Š è¾¨è­˜çµæœ")
    
    # é¡¯ç¤ºæœ€çµ‚ä½¿ç”¨çš„ä¿¡å¿ƒåº¦ (è®“ä½ çŸ¥é“ AI å¤šåŠªåŠ›)
    if final_conf < 0.4:
        st.caption(f"â„¹ï¸ å·²è‡ªå‹•é™ä½ä¿¡å¿ƒåº¦è‡³ **{final_conf}** ä»¥ç²å–æ›´å¤šæ•¸å­—")

    col1, col2 = st.columns(2)
    with col1:
        if len(reading_str) >= 4:
            st.metric("ğŸ”¥ åº¦æ•¸", reading_str)
        else:
            # å¦‚æœé™åˆ°æœ€ä½é‚„æ˜¯æŠ“ä¸åˆ°ï¼Œé¡¯ç¤ºç´…è‰²è­¦å‘Š
            st.metric("ğŸ”¥ åº¦æ•¸", reading_str if reading_str else "N/A", delta="ä½æ•¸ä¸è¶³" if reading_str else "æœªåµæ¸¬", delta_color="inverse")
            
    with col2:
        if len(serial_str) >= 6:
            st.metric("ğŸ”¢ è¡¨è™Ÿ", serial_str)
        else:
             st.metric("ğŸ”¢ è¡¨è™Ÿ", serial_str if serial_str else "N/A", delta="ä½æ•¸ä¸è¶³" if serial_str else "æœªåµæ¸¬", delta_color="inverse")
            
    st.divider()

    img_tab1, img_tab2 = st.tabs(["ğŸ‘ï¸ è¾¨è­˜çµæœåœ–", "ğŸ“· åŸå§‹åœ–ç‰‡"])
    
    with img_tab1:
        st.image(processed_img, caption=f"AI ç¹ªè£½æ¡†ç·š (Conf: {final_conf})", use_container_width=True)
    with img_tab2:
        st.image(image_source, caption="åŸå§‹ä¸Šå‚³", use_container_width=True)

